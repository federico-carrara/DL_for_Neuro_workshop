{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for EEG data analysis\n",
    "We have already seen from a more theoretical point of view what Deep Learning models are and what they are meant for. <br>\n",
    "Now it is time to understand how to use these models with Python!! <br>\n",
    "\n",
    "In the following, we will see a complete pipeline for the task of <span style=\"color:orange\">Emotion Recognition from EEG data</span> using the SEED dataset (Zheng et al., 2015, https://bcmi.sjtu.edu.cn/home/seed). <br>\n",
    "\n",
    "The workflow is composed of the following steps:\n",
    "\n",
    "<span style=\"font-size:24px\">1. Data Loading & Preprocessing</span><br>\n",
    "<span style=\"font-size:24px\">2. Model Definition</span><br>\n",
    "<span style=\"font-size:24px\">3. Model Training</span><br>\n",
    "<span style=\"font-size:24px\">4. Model Evaluation</span><br>\n",
    "\n",
    "We will go over every step, one at the time, discussing the problem and trying to find a solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll report here a brief description of the SEED dataset collection (from https://bcmi.sjtu.edu.cn/home/seed/seed.html):\n",
    "\n",
    "*\"Fifteen Chinese film clips (positive, neutral and negative emotions) were chosen from the pool of materials as stimuli used in the experiments. [...] The duration of each film clip is approximately 4 minutes. Each film clip is well edited to create coherent emotion eliciting and maximize emotional meanings. [...] There is a total of 15 trials (ed. movies) for each experiment. There was a 5 s hint before each clip, 45 s for self-assessment and 15 s to rest after each clip in one session. The order of presentation is arranged in such a way that two film clips that target the same emotion are not shown consecutively. For feedback, the participants were told to report their emotional reactions to each film clip by completing the questionnaire immediately after watching each clip. [...] [EEG signals] were collected with the 62-channel ESI NeuroScan System.\"*\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"./images/Data_collection_setup.png\" alt=\"exp_setup\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataset can be summarized as follows:\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"./images/dataset_schema.png\" alt=\"exp_setup\" width=\"1000\" height=\"500\"></div>\n",
    "\n",
    "Finally, it is worth mentioning that the provided data were **downsampled** at **200Hz** and a **bandpass frequency filter** from **0 - 75 Hz** was applied. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-size:24px\"><em>A bit of Math</em></span>\n",
    "\n",
    "As we discussed before, Deep Learning is all about Linear Algebra and tensors. Let's write down a *Legend* to fix symbols for the dimensions of our dataset. <br>\n",
    "<div style=\"text-align:left\">\n",
    "    <p style=\"font-size:24px;\">- N: <small><em>number of EEG recordings</em></small><br> - C: <small><em>number of EEG channels</em></small><br> - L: <small><em>EEG signal length</em></small><br></p>\n",
    "</div>\n",
    "\n",
    "Now, if we call the dataset containing the EEG signals as $X$ and the associated labels as $y$, we have tha $X$ and $y$ are tensors of size:\n",
    "    $$X \\in [N \\times C \\times L],$$    $$y \\in [N]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load, Extract and Transform\n",
    "The first step is to **load** data from file, **extract** the meaningful information, and **transform** them into a proper format. \n",
    "\n",
    "<span style=\"color:orange;font-size:18px\">This step requires some proficiency with file and data handling, plus some experience with Pytorch tensors manipulation, and, hence, it goes  bit out of the scope of this tutorial. <br>\n",
    "Anyway, for who's interested, the code used to manipulate the input data is available at: https://github.com/federico-carrara/DL_for_Neuro_workshop/blob/main/dataset.py</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Data preprocessing\n",
    "<span style=\"color:orange;font-size:20px\"><em>Deep Learning models are powerful feature extractors that can deal with unstructured data. <br></em></span>\n",
    "\n",
    "Well, in principle, that's true. However, in practice, the signal-to-noise ratio for most of data source is very low. <br>\n",
    "So, if we input our model with noisy data, most of the times we end up in a *garbage-in-garbage-out* situation:\n",
    "<div style=\"text-align:center\"><img src=\"./images/gigo.png\" alt=\"gigo\"></div>\n",
    "\n",
    "Therefore, **data preprocessing** is an essential step in all data analysis pipelines. <br>\n",
    "Specifically, in this case, we do the following:\n",
    "\n",
    "<span style=\"font-size:24px\">I) Division of the EEG signals in overlapping windows</span><br>\n",
    "Each of the input signals covers 4 minutes of EEG recording downsampled at 200Hz. Hence each signal is made of ~48k timepoints!!!<br>\n",
    "Splitting each signal into windows spanning 1, 5, or 10 seconds allows us to have more handy and still informative data. \n",
    "<div style=\"text-align:left\"><img src=\"./images/window_overlap.png\" alt=\"overlap\" height=300, width=400></div>\n",
    "\n",
    "Why overlapping windows?? It is an example of *Data Augmentation*!\n",
    "\n",
    "<span style=\"color:red\">A bit of Math:</span> after this step $X \\in [\\hat{N} \\times C \\times W]$ and $y \\in [\\hat{N}]$, where $W$ = window length, and $\\hat{N} \\approx \\frac{L}{W}$\n",
    "\n",
    "<span style=\"font-size:24px\">II) Extraction of EEG sub-bands</span><br>\n",
    "We apply a *Butterworth filter* to extract 4 sub-signals with frequencies in the *Theta*, *Alpha*, *Beta* and *Gamma* ranges.\n",
    "\n",
    "<span style=\"color:red\">A bit of Math:</span> after this step $X \\in [\\hat{N} \\times F \\times C \\times W]$ and $y \\in [\\hat{N}]$, where $F$ = 4, is the number of sub-bands.\n",
    "\n",
    "<span style=\"font-size:24px\">III) Computation of <em>channel-wise</em> Differential Entropy </span><br>\n",
    "Intuitively, the **Differential Entropy** is a measure of the *dispersion* of the distribution of a continuous variable. <br>\n",
    "Assuming that the EEG signal is the set of *realizations* of a *Gaussian* random variable, we get that the **Differential Entropy** for a given signal $S$ (with standard deviation $\\sigma$) can be computed as:\n",
    "$$DE(S) = \\frac{1}{2} \\log_2{2\\pi e \\sigma}$$\n",
    "Therefore, given a signal as input, we compute a single number as output. As a result from 62 windows, each one corresponding to a different channel, we get a single vector of 62 values.<br>\n",
    "We compute the $DE$ separately on every channel of each window. \n",
    "\n",
    "<span style=\"color:red\">A bit of Math:</span> after this step $X \\in [\\hat{N} \\times F \\times C]$ and $y \\in [\\hat{N}]$.\n",
    "\n",
    "<span style=\"font-size:24px\">IV) Standardization of data <em>by-trial</em></span><br>\n",
    "A challenging problem when dealing with EEG data is that the signals are extremely *subject* and *trial-dependent*. <br>\n",
    "Standardizing the data *by-trial* enables us to lower the *within-trial* variability of the data, so that the model is able to focus more on the *between-trials* variability\n",
    "\n",
    "<span style=\"color:red\">A bit of Math:</span> standardization does not alter the size of the data tensors.\n",
    "\n",
    "<span style=\"font-size:24px\"><span style=\"color:magenta\">V) Option 1:</span> Concatenation of sub-bands vector</span><br>\n",
    "To make the transformed data suitable for training a *Neural Network* we **concatenate** sub-band vectors in one single vector.\n",
    "\n",
    "<span style=\"color:red\">A bit of Math:</span> after this step $X \\in [\\hat{N} \\times (F*C)]$\n",
    "\n",
    "<span style=\"font-size:24px\"><span style=\"color:cyan\">V) Option 2:</span> Mapping to Electrode Grid</span><br>\n",
    "Instead of concatenating vectors, we can think to map the value computed from each electrode to a 2D grid, whose cells represent the position of a given electrode. In this way we can additionally exploit the information about the relative position of electrodes.\n",
    "\n",
    "<div style=\"display: flex; justify-content: left;\">\n",
    "  <img src=\"./images/Electrode_pos.png\" style=\"width: 25%;\">\n",
    "  <img src=\"./images/map_to_grid.png\" style=\"width: 70%;\">\n",
    "</div>\n",
    "\n",
    "<span style=\"color:red\">A bit of Math:</span> after this step $X \\in [\\hat{N} \\times F \\times 9 \\times 9]$, as the grid size to accomodate all the 62 electrodes has size $9 \\times 9$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:orange;font-size:18px\">The preprocessing of a large dataset like SEED may take several minutes of computation. Therefore, for the workshop you are provided with the already preprocess data (for different window size and both the concatenation and grid options).\n",
    "\n",
    "Once again, the code used to manipulate the input data is available at: https://github.com/federico-carrara/DL_for_Neuro_workshop/blob/main/dataset.py</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It's finally time to play a bit with the data!!!\n",
    "As we mentioned we have two types of inputs for the Deep learning models:\n",
    "- <span style=\"color:magenta\">Concatenated data</span>\n",
    "- <span style=\"color:cyan\">Data mapped to 2D grid</span>\n",
    "\n",
    "Clearly, depending on the particular input, we would need to use a different Neural Network to process them. <br>\n",
    "Namely we will use:\n",
    "- <span style=\"color:magenta\">A Feed Forward Neural Network (FFNN)</span>\n",
    "- <span style=\"color:cyan\">A Convolutional Neural Network (CNN)</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:magenta\">Option 1: Concatenated Data and Feed Forward Neural Network</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset_v2 import SEEDDataset\n",
    "from FFNN_model import EEGFeedForwardNet, EEGFeedForwardNetModel\n",
    "import pytorch_lightning as pl\n",
    "from torchsummary import summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define window length, batch size, and the path to the preprocessed data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 1000 # possible values: [200, 1000, 2000]\n",
    "batch_sz = 16 # possible values: [8,16,32,64,128,256,512]\n",
    "\n",
    "dataset_type = \"concatenated\" # possible values: [\"concatenated\", \"grid\"]\n",
    "\n",
    "path_to_training_data = f\"../data/processed_data_{dataset_type}/train_data_processed_win{window_length}_{dataset_type}.h5\"\n",
    "path_to_validation_data = f\"../data/processed_data_{dataset_type}/valid_data_processed_win{window_length}_{dataset_type}.h5\"\n",
    "path_to_test_data = f\"../data/processed_data_{dataset_type}/test_data_processed_win{window_length}_{dataset_type}.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed train data at ../data/processed_data_concatenated/train_data_processed_win2000_concatenated.h5...\n",
      "Loading preprocessed validation data at ../data/processed_data_concatenated/valid_data_processed_win2000_concatenated.h5...\n",
      "Loading preprocessed test data at ../data/processed_data_concatenated/test_data_processed_win2000_concatenated.h5...\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SEEDDataset(\n",
    "    path_to_preprocessed=path_to_training_data,\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "val_dataset = SEEDDataset(\n",
    "    path_to_preprocessed=path_to_validation_data,\n",
    "    split=\"validation\"\n",
    ")\n",
    "\n",
    "test_dataset = SEEDDataset(\n",
    "    path_to_preprocessed=path_to_test_data,\n",
    "    split=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Data Loaders <small>(objects that automatically prepare data to be fed in the network)</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_sz, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_sz, shuffle=False, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_sz, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"input_size\": 248, # BETTER LEAVE LIKE THIS\n",
    "    \"num_classes\": 3, # BETTER LEAVE LIKE THIS\n",
    "    \"dropout_prob\": 0.25, # possible values: any in the interval [0, 0.8] \n",
    "    \"hidden_size\": 64,\n",
    "    \"norm_method\": \"batch\" # BETTER LEAVE LIKE THIS\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Neural Network to inspect its structure *(not needed for training)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn_model = EEGFeedForwardNetModel(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "       BatchNorm1d-1                  [16, 248]             496\n",
      "            Linear-2                   [16, 64]          15,936\n",
      "       BatchNorm1d-3                   [16, 64]             128\n",
      "              ReLU-4                   [16, 64]               0\n",
      "           Dropout-5                   [16, 64]               0\n",
      "            Linear-6                   [16, 64]           4,160\n",
      "       BatchNorm1d-7                   [16, 64]             128\n",
      "              ReLU-8                   [16, 64]               0\n",
      "           Dropout-9                   [16, 64]               0\n",
      "           Linear-10                   [16, 64]           4,160\n",
      "      BatchNorm1d-11                   [16, 64]             128\n",
      "             ReLU-12                   [16, 64]               0\n",
      "          Dropout-13                   [16, 64]               0\n",
      "           Linear-14                    [16, 3]             195\n",
      "             ReLU-15                    [16, 3]               0\n",
      "================================================================\n",
      "Total params: 25,331\n",
      "Trainable params: 25,331\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 0.12\n",
      "Params size (MB): 0.10\n",
      "Estimated Total Size (MB): 0.24\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(\n",
    "    model=ffnn_model, \n",
    "    input_size=(248,),\n",
    "    batch_size=batch_sz, \n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {    \n",
    "    \"lr\": 5e-4, # possible values: any in the interval [1e-6, 1e-2]\n",
    "    \"betas\": [0.9, 0.99], # BETTER LEAVE LIKE THIS\n",
    "    \"weight_decay\": 1e-6, # BETTER LEAVE LIKE THIS\n",
    "    \"epochs\": 20, # possible values: any (but be careful to check for overfitting!!)\n",
    "    \"lr_patience\": 3 # possible values: no more than 1/3 of `epochs` is a reasonable value\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the actual trainable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffnn_net = EEGFeedForwardNet(\n",
    "    model_parameters=model_params,\n",
    "    **training_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful stuff for training (BETTER LEAVE LIKE THIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    filename=\"best_checkpoint\",\n",
    ")\n",
    "\n",
    "last_checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    save_last=True,\n",
    "    filename=\"last_checkpoint_at_{epoch:02d}\",\n",
    ")\n",
    "\n",
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type                   | Params\n",
      "----------------------------------------------------\n",
      "0 | loss_fun | CrossEntropyLoss       | 0     \n",
      "1 | model    | EEGFeedForwardNetModel | 25.3 K\n",
      "----------------------------------------------------\n",
      "25.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "25.3 K    Total params\n",
      "0.101     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a616a51f174c76b5da11d55234a800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647589f8b9cd45ed92520a27b10eab30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332378a473d747508df151a192ac232e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec5dbd14a9146d4ad3f11f5c1dd0063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf13531844014a34bef72ea8b5b4932d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15933aa2e4974111a44d0f7087e59817",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9482492f1c594688894208cfa1cade82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7acb89b29ad240588c171ecca091a7c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3733f0dd46f74a9884aa56d5c7144b2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e5df526ab1e48e68631afb7b18c82ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615d5a48820441f7b9597ee5cbb3a22e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6851399e3fc74ff6a1581cbf8d6a3171",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e846eb3240dd408db2c79c6fe1f3810a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec2079d66bc4be297e2daae3a414f03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5cbf21c7c4d478b86c97b3f6bcc8291",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8222d2434cb9485089e2374deadf575b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9340994d11ac45b7a92498463ced2660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc4e805ec9e4ff186ee713e90b6dc68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42daa26a20ed4e3f8dcac44ce87cf157",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af0a7c7b3b034831be2c180d464654ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168930574202407982af4c918cb0875a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2c6e34d14a48c3927f92c09686df05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=training_params[\"epochs\"], \n",
    "    callbacks=[best_checkpoint_callback, last_checkpoint_callback, lr_monitor])\n",
    "trainer.fit(ffnn_net, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:cyan\">Option 2: Data mapped to 2D grid and Convolutional Neural Network</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset_v2 import SEEDDataset\n",
    "from CNN_model import CCNN, CCNNModel\n",
    "import pytorch_lightning as pl\n",
    "from torchsummary import summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define window length, batch size, and the path to the preprocessed data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 1000 # possible values: [200, 1000, 2000]\n",
    "batch_sz = 16 # possible values: [8,16,32,64,128,256,512]\n",
    "\n",
    "dataset_type = \"grid\" # possible values: [\"concatenated\", \"grid\"]\n",
    "\n",
    "path_to_training_data = f\"../data/processed_data_{dataset_type}/train_data_processed_win{window_length}_{dataset_type}.h5\"\n",
    "path_to_validation_data = f\"../data/processed_data_{dataset_type}/valid_data_processed_win{window_length}_{dataset_type}.h5\"\n",
    "path_to_test_data = f\"../data/processed_data_{dataset_type}/test_data_processed_win{window_length}_{dataset_type}.h5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed train data at ../data/processed_data_grid/train_data_processed_win1000_grid.h5...\n",
      "Loading preprocessed validation data at ../data/processed_data_grid/valid_data_processed_win1000_grid.h5...\n",
      "Loading preprocessed test data at ../data/processed_data_grid/test_data_processed_win1000_grid.h5...\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SEEDDataset(\n",
    "    path_to_preprocessed=path_to_training_data,\n",
    "    split=\"train\"\n",
    ")\n",
    "\n",
    "val_dataset = SEEDDataset(\n",
    "    path_to_preprocessed=path_to_validation_data,\n",
    "    split=\"validation\"\n",
    ")\n",
    "\n",
    "test_dataset = SEEDDataset(\n",
    "    path_to_preprocessed=path_to_test_data,\n",
    "    split=\"test\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Data Loaders <small>(objects that automatically prepare data to be fed in the network)</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_sz, shuffle=True, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_sz, shuffle=False, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_sz, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"input_ch\": 4, # BETTER LEAVE LIKE THIS\n",
    "    \"grid_size\": (9, 9), # BETTER LEAVE LIKE THIS\n",
    "    \"num_classes\": 3, # BETTER LEAVE LIKE THIS\n",
    "    \"output_ch\":  128, # possible values: [8, 16, 32, 64, 128]\n",
    "    \"kernel_size\":  4, # possible values: [3, 4, 5]\n",
    "    \"hidden_size\":  1024, # possible values: [128, 256, 512, 1024]\n",
    "    \"dropout_prob\": 0.25, # possible values: any in the interval [0, 0.8] \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Neural Network to inspect its structure *(not needed for training)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = CCNNModel(**model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [16, 128, 9, 9]           8,320\n",
      "              ReLU-2            [16, 128, 9, 9]               0\n",
      "            Conv2d-3            [16, 256, 9, 9]         524,544\n",
      "              ReLU-4            [16, 256, 9, 9]               0\n",
      "            Conv2d-5            [16, 512, 9, 9]       2,097,664\n",
      "              ReLU-6            [16, 512, 9, 9]               0\n",
      "            Conv2d-7            [16, 128, 9, 9]       1,048,704\n",
      "              ReLU-8            [16, 128, 9, 9]               0\n",
      "            Linear-9                 [16, 1024]      10,617,856\n",
      "             SELU-10                 [16, 1024]               0\n",
      "        Dropout2d-11                 [16, 1024]               0\n",
      "           Linear-12                    [16, 3]           3,075\n",
      "================================================================\n",
      "Total params: 14,300,163\n",
      "Trainable params: 14,300,163\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 20.63\n",
      "Params size (MB): 54.55\n",
      "Estimated Total Size (MB): 75.20\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local0/fcarrara/mambaforge/envs/brain_DL/lib/python3.10/site-packages/torch/nn/functional.py:1345: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "summary(\n",
    "    model=cnn_model, \n",
    "    input_size=(4, 9, 9),\n",
    "    batch_size=batch_sz, \n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_params = {    \n",
    "    \"lr\": 5e-4, # possible values: any in the interval [1e-6, 1e-2]\n",
    "    \"betas\": [0.9, 0.99], # BETTER LEAVE LIKE THIS\n",
    "    \"weight_decay\": 1e-6, # BETTER LEAVE LIKE THIS\n",
    "    \"epochs\": 20, # possible values: any (but be careful to check for overfitting!!)\n",
    "    \"lr_patience\": 3 # possible values: no more than 1/3 of `epochs` is a reasonable value\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the actual trainable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_net = CCNN(\n",
    "    model_parameters=model_params,\n",
    "    **training_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful stuff for training (BETTER LEAVE LIKE THIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    save_top_k=1,\n",
    "    monitor=\"val_loss\",\n",
    "    mode=\"min\",\n",
    "    filename=\"best_checkpoint\",\n",
    ")\n",
    "\n",
    "last_checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    save_last=True,\n",
    "    filename=\"last_checkpoint_at_{epoch:02d}\",\n",
    ")\n",
    "\n",
    "lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type             | Params\n",
      "----------------------------------------------\n",
      "0 | loss_fun | CrossEntropyLoss | 0     \n",
      "1 | model    | CCNNModel        | 14.3 M\n",
      "----------------------------------------------\n",
      "14.3 M    Trainable params\n",
      "0         Non-trainable params\n",
      "14.3 M    Total params\n",
      "57.201    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d0e0b67c234235a401ed244f7abe26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9d82b11b1945b1a9edb5cd6139cdbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "775d9d7a135048db8dc5b8e33d3202ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ee835399594596974acfc0bdf733eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6037c972671c43b9b74d51edbf2ce47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbc1a39a984040248145809c20164656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a1acfcbd2b4c8d8c1347a1b3a948af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12406e50adac45e18e40851f7d6a40ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local0/fcarrara/mambaforge/envs/brain_DL/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    max_epochs=training_params[\"epochs\"], \n",
    "    callbacks=[best_checkpoint_callback, last_checkpoint_callback, lr_monitor])\n",
    "trainer.fit(cnn_net, train_dataloader, val_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is your turn to experiment!\n",
    "Try to train and evaluate your own model. <br>\n",
    "\n",
    "You can customize:\n",
    "<p style=\"font-size:24px\">\n",
    "- Window Size <br>\n",
    "- <span style=\"color:magenta\"><em>Concatenated</em></span> vs <span style=\"color:cyan\"><em>Mapped to Grid</em></span> data <br>\n",
    "- <span style=\"color:magenta\"><em>FFNN</em></span> vs <span style=\"color:cyan\"><em>CNN</em></span> model <br>\n",
    "- Model parameters <br>\n",
    "- Training parameters <br>\n",
    "</p>\n",
    "\n",
    "Notice that next to every parameter there is a comment with the suggested range to get reasonable resuls. <br>\n",
    "There is a few parameters that is better not to touch (they are marked with *BETTER LEAVE LIKE THIS*). <br>\n",
    "Finally, it is important to remark that *Concatenated data* works only with the *FFNN* model, whereas the *Mapped to grid data* works only with the CNN.\n",
    "\n",
    "<p style=\"font-size:24px; color:orange\">GOOD LUCK WITH YOUR TRAININGS!!</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset_v2 import SEEDDataset\n",
    "from CNN_model import CCNN\n",
    "from FFNN_model import EEGFeedForwardNet\n",
    "import pytorch_lightning as pl\n",
    "from torchsummary import summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load preprocessed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define window length, batch size, and the path to the preprocessed data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Data Loaders <small>(objects that automatically prepare data to be fed in the network)</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the actual trainable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some useful stuff for training (BETTER LEAVE LIKE THIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for EEG data analysis\n",
    "We have already seen from a more theoretical point of view what Deep Learning models are and what they are meant for. <br>\n",
    "Now it is time to understand how to use these models with Python!! <br>\n",
    "\n",
    "In the following, we will see a complete pipeline for the task of <span style=\"color:orange\">Emotion Recognition from EEG data</span> using the SEED dataset (Zheng et al., 2015, https://bcmi.sjtu.edu.cn/home/seed). <br>\n",
    "\n",
    "The workflow is composed of the following steps:\n",
    "\n",
    "<span style=\"font-size:24px\">1. Data Loading & Preprocessing</span><br>\n",
    "<span style=\"font-size:24px\">2. Model Definition</span><br>\n",
    "<span style=\"font-size:24px\">3. Model Training</span><br>\n",
    "<span style=\"font-size:24px\">4. Model Evaluation</span><br>\n",
    "\n",
    "We will go over every step, one at the time, discussing the problem and trying to find a solution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll report here a brief description of the SEED dataset collection (from https://bcmi.sjtu.edu.cn/home/seed/seed.html):\n",
    "\n",
    "*\"Fifteen Chinese film clips (positive, neutral and negative emotions) were chosen from the pool of materials as stimuli used in the experiments. [...] The duration of each film clip is approximately 4 minutes. Each film clip is well edited to create coherent emotion eliciting and maximize emotional meanings. [...] There is a total of 15 trials (ed. movies) for each experiment. There was a 5 s hint before each clip, 45 s for self-assessment and 15 s to rest after each clip in one session. The order of presentation is arranged in such a way that two film clips that target the same emotion are not shown consecutively. For feedback, the participants were told to report their emotional reactions to each film clip by completing the questionnaire immediately after watching each clip. [...] [EEG signals] were collected with the 62-channel ESI NeuroScan System.\"*\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"./images/Data_collection_setup.png\" alt=\"exp_setup\"></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting dataset can be summarized as follows:\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"./images/dataset_schema.png\" alt=\"exp_setup\" width=\"1000\" height=\"500\"></div>\n",
    "\n",
    "Finally, it is worth mentioning that the provided data were **downsampled** at **200Hz** and a **bandpass frequency filter** from **0 - 75 Hz** was applied. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red;font-size:24px\"><em>A bit of Math</em></span>\n",
    "\n",
    "As we discussed before, Deep Learning is all about Linear Algebra and tensors. Let's write down a *Legend* to fix symbols for the dimensions of our dataset. <br>\n",
    "<div style=\"text-align:left\">\n",
    "    <p style=\"font-size:24px;\">- N: <small><em>number of EEG recordings</em></small><br> - C: <small><em>number of EEG channels</em></small><br> - L: <small><em>EEG signal length</em></small><br></p>\n",
    "</div>\n",
    "\n",
    "Now, if we call the dataset containing the EEG signals as $X$ and the associated labels as $y$, we have tha $X$ and $y$ are tensors of size:\n",
    "    $$X \\in [N \\times C \\times L],$$    $$y \\in [N]$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load, Extract and Transform\n",
    "The first step is to **load** data from file, **extract** the meaningful information, and **transform** them into a proper format. \n",
    "\n",
    "<span style=\"color:orange;font-size:18px\">This process require some proficiency with file and data handling, plus some experience with Pytorch tensors manipulation, and, hence, it goes  bit out of the scope of this tutorial. <br>\n",
    "Anyway, for who's interested, the code used to manipulate the input data is available at: https://github.com/federico-carrara/DL_for_Neuro_workshop/blob/main/dataset.py</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Data preprocessing\n",
    "<span style=\"color:orange;font-size:20px\"><em>Deep Learning models are powerful feature extractors that can deal with unstructured data. <br></em></span>\n",
    "\n",
    "Well, in principle, that's true. However, in practice, the signal-to-noise ratio for most of data source is very low. <br>\n",
    "So, if we input our model with noisy data, most of the times we end up in a *garbage-in-garbage-out* situation:\n",
    "<div style=\"text-align:center\"><img src=\"./images/gigo.png\" alt=\"gigo\"></div>\n",
    "\n",
    "Therefore, **data preprocessing** is an essential step in all data analysis pipelines. <br>\n",
    "Specifically, in this case, we do the following:\n",
    "\n",
    "<span style=\"font-size:24px\">I) Division of the EEG signals in overlapping windows</span><br>\n",
    "Each of the input signals covers 4 minutes of EEG recording downsampled at 200Hz. Hence each signal is made of ~48k timepoints!!!<br>\n",
    "Splitting each signal into windows spanning 1, 5, or 10 seconds allows us to have more handy and still informative data. \n",
    "<div style=\"text-align:left\"><img src=\"./images/window_overlap.png\" alt=\"gigo\" height=300, width=400></div>\n",
    "\n",
    "Why overlapping windows?? It is an example of *Data Augmentation*!\n",
    "\n",
    "<span style=\"color:red\">A bit of Math:</span> after this step $X \\in [\\hat{N} \\times C \\times W]$ and $y \\in [\\hat{N}]$, where $W$ = window length, and $\\hat{N} \\approx \\frac{L}{W}$\n",
    "\n",
    "<span style=\"font-size:24px\">II) Extraction of EEG sub-bands</span><br>\n",
    "We apply a *Butterworth filter* to extract 4 sub-signals with frequencies in the *Theta*, *Alpha*, *Beta* and *Gamma* ranges.\n",
    "\n",
    "<span style=\"color:red\">A bit of Math:</span> after this step $X \\in [\\hat{N} \\times F \\times C \\times W]$ and $y \\in [\\hat{N}]$, where $F$ = 4, is the number of sub-bands.\n",
    "\n",
    "<span style=\"font-size:24px\">III) Computation of <em>channel-wise</em> Differential Entropy </span><br>\n",
    "Intuitively, the **Differential Entropy** is a measure of the *dispersion* of the distribution of a continuous variable. <br>\n",
    "Assuming that the EEG signal is the set of *realizations* of a *Gaussian* random variable, we get that the **Differential Entropy** for a given signal $S$ (with standard deviation $\\sigma$) can be computed as:\n",
    "$$DE(S) = \\frac{1}{2} \\log_2{2\\pi e \\sigma}$$\n",
    "Therefore, given a signal as input, we compute a single number as output. As a result from 62 windows, each one corresponding to a different channel, we get a single vector of 62 values.<br>\n",
    "We compute the $DE$ separately on every channel of each window. \n",
    "\n",
    "<span style=\"color:red\">A bit of Math:</span> after this step $X \\in [\\hat{N} \\times F \\times C]$ and $y \\in [\\hat{N}]$.\n",
    "\n",
    "<span style=\"font-size:24px\">IV) Standardization of data <em>by-trial</em></span><br>\n",
    "A challenging problem when dealing with EEG data is that the signals are extremely *subject* and *trial-dependent*. <br>\n",
    "Standardizing the data *by-trial* enables us to lower the *within-trial* variability of the data, so that the model is able to focus more on the *between-trials* variability\n",
    "\n",
    "<span style=\"color:red\">A bit of Math:</span> standardization does not alter the size of the data tensors.\n",
    "\n",
    "<span style=\"font-size:24px\"><span style=\"color:magenta\">V) Option 1:</span> Concatenation of sub-bands vector</span><br>\n",
    "To make the transformed data suitable for training a *Neural Network* we **concatenate** sub-band vectors in one single vector.\n",
    "\n",
    "<span style=\"color:red\">A bit of Math:</span> after this step $X \\in [\\hat{N} \\times (F*C)]$\n",
    "\n",
    "<span style=\"font-size:24px\"><span style=\"color:cyan\">V) Option 2:</span> Mapping to Electrode Grid <em>(optional)</em></span><br>\n",
    "Instead of concatenating vectors, we can think to map the value computed from each electrode to a 2D grid, whose cells represent the position of a given electrode.\n",
    "\n",
    "\n",
    "The information about the position of the electrodes from which data were collected can be helpful to allow the model to focus at once at the signals from neighboring electrode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

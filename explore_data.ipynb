{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from utils import  TrainDataset, EEGNetModel\n",
    "from torchsummary import summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "The dataset contains the EEG recordings of 15 subjects. For each subject, we have 15 different recordings, each one collected while watching a different movie clip. Each clip is associated to an emotional state amon {sad: -1, neutral: 0, happy: 1}. EEG recordings comprises 62 channels.\n",
    "\n",
    "N.B. Recordings correspondent to the same movies have the same length, while recordings correspondent to different movies have different length (iun general). How to do? No problem, since we are taking sub windows of the signals.\n",
    "\n",
    "Data have been preprocessed by downsampling signals to 200Hz, segmentating the signals such that it corresponds to the length of the movie and applying a band-pass filter at 0-75Hz. Since recordings are about 4 minutes long and are now sampled at 200Hz, they contain roughly 48k time points each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data files: 100%|██████████| 45/45 [01:05<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset = TrainDataset(\"data/Preprocessed_EEG\", \"data/Preprocessed_EEG/label.mat\", 1000, 100, False)\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 62, 1000])\n",
      "torch.Size([2, 16, 62, 1000])\n",
      "torch.Size([2, 32, 56, 1000])\n",
      "torch.Size([2, 32, 28, 200])\n",
      "torch.Size([2, 32, 28, 200])\n",
      "torch.Size([2, 32, 14, 40])\n",
      "torch.Size([2, 17920])\n",
      "torch.Size([2, 128])\n",
      "torch.Size([2, 3])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 62, 1000]           1,040\n",
      "       BatchNorm2d-2         [-1, 16, 62, 1000]              32\n",
      "            Conv2d-3         [-1, 32, 56, 1000]           3,616\n",
      "       BatchNorm2d-4         [-1, 32, 56, 1000]              64\n",
      "              ReLU-5         [-1, 32, 56, 1000]               0\n",
      "         AvgPool2d-6          [-1, 32, 28, 200]               0\n",
      "           Dropout-7          [-1, 32, 28, 200]               0\n",
      "            Conv2d-8          [-1, 32, 28, 200]          16,416\n",
      "            Conv2d-9          [-1, 32, 28, 200]           1,056\n",
      "      BatchNorm2d-10          [-1, 32, 28, 200]              64\n",
      "             ReLU-11          [-1, 32, 28, 200]               0\n",
      "        AvgPool2d-12           [-1, 32, 14, 40]               0\n",
      "          Dropout-13           [-1, 32, 14, 40]               0\n",
      "          Flatten-14                [-1, 17920]               0\n",
      "           Linear-15                  [-1, 128]       2,293,888\n",
      "      BatchNorm1d-16                  [-1, 128]             256\n",
      "             ReLU-17                  [-1, 128]               0\n",
      "          Dropout-18                  [-1, 128]               0\n",
      "           Linear-19                    [-1, 3]             387\n",
      "================================================================\n",
      "Total params: 2,316,819\n",
      "Trainable params: 2,316,819\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.24\n",
      "Forward/backward pass size (MB): 64.77\n",
      "Params size (MB): 8.84\n",
      "Estimated Total Size (MB): 73.84\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = EEGNetModel(input_size=(62, 1000))\n",
    "summary(model, (1, 62, 1000), batch_size=-1, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 62, 1000]) torch.float32\n",
      "torch.Size([16]) torch.int16\n"
     ]
    }
   ],
   "source": [
    "print(batch1[0].shape, batch1[0].dtype)\n",
    "print(batch1[1].shape, batch1[1].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(batch1[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

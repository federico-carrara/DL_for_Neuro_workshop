{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Exploration\n",
    "The dataset contains the EEG recordings for 15 subjects. Each subject performed the experiment 3 times, giving a total of 15 EEG sessions. \n",
    "\n",
    "For each session, 15 different EEG signal have been recorded, each one associated to the task of watching a different movie clip. Each clip is associated to an emotional state, namely {sad: -1, neutral: 0, happy: 1}. \n",
    "\n",
    "EEG recordings comprises 62 channels and lasts around 4 minutes. Specifically, recordings correspondent to the same movies have the same length, while recordings correspondent to different movies have different length (in general).\n",
    "\n",
    "Data have been preprocessed by downsampling signals to 200Hz, segmentating the signals such that it corresponds to the length of the movie and applying a band-pass filter at 0-75Hz. Since recordings are about 4 minutes long and are now sampled at 200Hz, they contain roughly 48k time points each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data files: 100%|██████████| 45/45 [01:09<00:00,  1.54s/it]\n"
     ]
    }
   ],
   "source": [
    "example_dataset = TrainDataset(\n",
    "    path_to_data_dir=\"data/Preprocessed_EEG/test\", \n",
    "    path_to_labels=\"data/Preprocessed_EEG/label.mat\", \n",
    "    win_length=1000, \n",
    "    win_overlap=100, \n",
    "    transform=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show how you can manipulate and plot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model definition and training\n",
    "In this section we do the following:\n",
    "\n",
    "- Load training, validation and test datasets.\n",
    "- Create an instance of the EEGNet model.\n",
    "- Train the EEGNet model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training, validation and test datasets\n",
    "We create Dataset and DataLoader for each data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset import TrainDataset, ValidationDataset, TestDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 1000\n",
    "window_overlap = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load training, validation and test datasets with the specific dataset objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading training data files:   0%|          | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading training data files: 100%|██████████| 36/36 [00:52<00:00,  1.46s/it]\n",
      "Loading validation data files: 100%|██████████| 6/6 [00:08<00:00,  1.44s/it]\n",
      "Loading test data files: 100%|██████████| 3/3 [00:04<00:00,  1.45s/it]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = TrainDataset(\n",
    "    path_to_data_dir=\"data/train/\", \n",
    "    path_to_labels=\"data/label.mat\", \n",
    "    win_length=window_length, \n",
    "    win_overlap=window_overlap, \n",
    "    data_augmentation=True\n",
    ")\n",
    "\n",
    "val_dataset = ValidationDataset(\n",
    "    path_to_data_dir=\"data/valid/\", \n",
    "    path_to_labels=\"data/label.mat\", \n",
    "    win_length=window_length, \n",
    "    win_overlap=window_overlap, \n",
    ")\n",
    "\n",
    "test_dataset = TestDataset(\n",
    "    path_to_data_dir=\"data/test/\", \n",
    "    path_to_labels=\"data/label.mat\", \n",
    "    win_length=window_length, \n",
    "    win_overlap=window_overlap,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to feed the data into the neural network we need a specific tool called *DataLoader*. This object enable to automatically *shuffle* the records in the dataset, then create *batches* of data of a specific size, which are suitable inputs for the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_sz, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_sz, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_sz, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand what's happening let's check the content of dataset and dataloader objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of datasets (number of windows)\n",
      "--------------------------------------\n",
      "Training dataset: 26820\n",
      "Validation dataset: 4470\n",
      "Test dataset: 2235\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of datasets (number of windows)\")\n",
    "print(\"--------------------------------------\")\n",
    "print(f\"Training dataset: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset: {len(val_dataset)}\")\n",
    "print(f\"Test dataset: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single dataset item\n",
      "Data: tensor([[[  5.6854,  -4.2185, -29.4796,  ..., -32.3536,  -4.6246,  -1.3064],\n",
      "         [-19.6733, -16.1599, -21.7344,  ..., -34.5277, -30.0970, -33.2164],\n",
      "         [-23.3691, -28.9452, -35.3163,  ..., -37.2978, -19.0721, -11.3794],\n",
      "         ...,\n",
      "         [ -0.5065,  -4.1457,  -2.9170,  ...,  51.4446,  47.2760,  46.2717],\n",
      "         [-18.0092, -22.8597, -13.6491,  ...,  52.7978,  44.3729,  44.7333],\n",
      "         [-28.1125, -28.6088, -35.9149,  ...,  50.1409,  55.9867,  51.4929]]])\n",
      "Data shape & type: torch.float32, torch.Size([1, 62, 1000])\n",
      "Label: 1\n",
      "Label shape & type: torch.int16, torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "first_elem = train_dataset[0]\n",
    "print(\"Single dataset item\")\n",
    "print(f\"Data: {first_elem[0]}\")\n",
    "print(f\"Data shape & type: {first_elem[0].dtype}, {first_elem[0].shape}\")\n",
    "print(f\"Label: {first_elem[1]}\")\n",
    "print(f\"Label shape & type: {first_elem[1].dtype}, {first_elem[1].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Neural Network Model\n",
    "We employ the class named `EEGNet` (from the script `model.py`) to build an object of the *EEGNet* neural network model we previously discussed.\n",
    "\n",
    "Here I create one instance of the model to inspect its structure by calling `EEGNetModel` constructor (i.e., the name of the class itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import EEGNetModel\n",
    "from torchsummary import summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sz = (1, 62, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_net_model = EEGNetModel(input_size=input_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [16, 16, 62, 1000]           1,040\n",
      "       BatchNorm2d-2         [16, 16, 62, 1000]              32\n",
      "            Conv2d-3         [16, 32, 56, 1000]           3,616\n",
      "       BatchNorm2d-4         [16, 32, 56, 1000]              64\n",
      "              ReLU-5         [16, 32, 56, 1000]               0\n",
      "         AvgPool2d-6          [16, 32, 28, 200]               0\n",
      "           Dropout-7          [16, 32, 28, 200]               0\n",
      "            Conv2d-8          [16, 32, 28, 200]          16,416\n",
      "            Conv2d-9          [16, 32, 28, 200]           1,056\n",
      "      BatchNorm2d-10          [16, 32, 28, 200]              64\n",
      "             ReLU-11          [16, 32, 28, 200]               0\n",
      "        AvgPool2d-12           [16, 32, 14, 40]               0\n",
      "          Dropout-13           [16, 32, 14, 40]               0\n",
      "          Flatten-14                [16, 17920]               0\n",
      "           Linear-15                  [16, 128]       2,293,888\n",
      "      BatchNorm1d-16                  [16, 128]             256\n",
      "             ReLU-17                  [16, 128]               0\n",
      "          Dropout-18                  [16, 128]               0\n",
      "           Linear-19                    [16, 3]             387\n",
      "================================================================\n",
      "Total params: 2,316,819\n",
      "Trainable params: 2,316,819\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 3.78\n",
      "Forward/backward pass size (MB): 1036.31\n",
      "Params size (MB): 8.84\n",
      "Estimated Total Size (MB): 1048.94\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(\n",
    "    model=eeg_net_model, \n",
    "    input_size=input_sz,\n",
    "    batch_size=batch_sz, \n",
    "    device=\"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "We employ the class named `EEGNet` (from the script `model.py`) to build an object of the *EEGNet* neural network model that provide internal functionalities for *training*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import EEGNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define variables for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    \"input_size\": (1, 62, 1000),\n",
    "    \"num_classes\": 3,\n",
    "    \"num_out_channels\": 16,\n",
    "    \"temporal_kernel_size\": 64,\n",
    "    \"spatial_kernel_size\": 7, \n",
    "    \"separable_kernel_size\": 16,\n",
    "    \"pooling_size\": (2, 5), \n",
    "    \"dropout_prob\": 0.5, \n",
    "    \"hidden_size\": 128,\n",
    "}\n",
    "\n",
    "training_params = {    \n",
    "    \"lr\": 1e-4, \n",
    "    \"betas\": [0.9, 0.99], \n",
    "    \"weight_decay\": 1e-6, \n",
    "    \"epochs\": 100, \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_net = EEGNet(\n",
    "    model_parameters=model_params,\n",
    "    **training_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain_DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
